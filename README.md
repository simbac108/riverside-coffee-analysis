# Riverside, CA Coffee Shop Market Analysis

## Project Goal

This project is a comprehensive data analysis and machine learning endeavor to identify "opportunity hotspots" for new coffee shops within Riverside County, California. The primary objective was to move beyond simple demographic assumptions and use a data-driven approach to find census tracts with high potential (e.g., high population/income) but low market saturation (few existing coffee shops).

The project started as an exploration of using machine learning for spatial predictions and evolved into a full end-to-end data science workflow, from data acquisition and cleaning to exploratory analysis and predictive modeling.

## Methodology & Workflow

The project was executed in three main phases:

### Phase 1: Data Acquisition & Processing

A unified, hyperlocal dataset was built from scratch by combining three distinct data sources:

1.  **Geographic Data:** Census tract boundary data for California was sourced from the **U.S. Census Bureau's TIGER/Line Shapefiles**. This was filtered down to Riverside County to create the geographic canvas for the analysis.
2.  **Demographic Data:** Key demographic metrics for each census tract (Total Population, Median Household Income, Median Age) were retrieved directly from the **U.S. Census Bureau's American Community Survey (ACS) API**.
3.  **Business/Competitor Data:** A comprehensive list of existing coffee shops, including their location, average rating, and total number of reviews, was gathered using the **Google Maps Places API** with a systematic grid-based search to ensure full coverage of the county.

These sources were combined into a single GeoJSON file where each feature represents a census tract and its associated attributes.

### Phase 2: Exploratory Data Analysis (EDA)

With the unified dataset, we performed visual and quantitative analysis to understand the market dynamics.

* **Geospatial Visualization:** Choropleth maps were created to visualize the spatial distribution of population, income, shop density, and a "Weighted Rating" score (which adjusts for the number of reviews).
* **Statistical Analysis:** A correlation matrix and scatter plots were generated to quantify the relationships between variables.

### Phase 3: Predictive Modeling

A machine learning model was trained to predict the "expected" number of coffee shops a tract could support based on its demographics.

* **Model:** A `HistGradientBoostingRegressor` from `scikit-learn` was used.
* **Features (X):** `TotalPopulation`, `MedianHouseholdIncome`, `MedianAge`.
* **Target (y):** `ShopCount`.
* **Goal:** The model's predictions were used to calculate an "Opportunity Score" (`PredictedShopCount` - `ActualShopCount`) to identify the most underserved tracts.

## Key Findings

The most significant insight from the analysis was that **the number of coffee shops in a given census tract has an extremely weak correlation with its residential population (0.06) or median household income (0.01).**

This suggests that the Riverside coffee shop market is not driven by simple residential demographics. The primary drivers are likely other factors not included in the initial model, such as:

* Daytime population (commuter work patterns)
* Proximity to commercial hubs, "downtown" areas, or universities
* Traffic flow and accessibility

This makes the data-driven list of "opportunity hotspots" generated by the model particularly valuable, as it identifies areas that have strong demographics but are being overlooked by the current market.

## How to Run This Project

1.  **Clone the repository:**
    ```bash
    git clone <your-repo-url>
    cd riverside-coffee-analysis
    ```
2.  **Create a Python Virtual Environment:**
    ```bash
    python3 -m venv .venv
    source .venv/bin/activate
    ```
3.  **Install Dependencies:**
    ```bash
    pip install -r requirements.txt
    ```
4.  **Set Up API Keys:**
    * Open `scripts/01_get_all_coffee_shops.py`.
    * Replace `'YOUR_API_KEY_HERE'` with your own Google Maps Places API key.
    * (Optional) You can get a Census API key and add it to the script for higher rate limits.
5.  **Run the Scripts in Order:**
    * Run the Google Maps scraper: `python3 scripts/01_get_all_coffee_shops.py`
    * Run the main processing pipeline and visualization: `python3 scripts/02_master_script.py`
    * Run the quantitative analysis: `python3 scripts/03_analyze_data.py`
    * Prepare data for the model: `python3 scripts/04_prepare_ml_data.py`
    * Train the model and get hotspot predictions: `python3 scripts/05_train_model.py`

## Future Work

The predictive model's performance was poor (Negative RÂ²), confirming that residential demographics are not sufficient features. The clear next step to improve the model is to engineer new features based on our findings, such as:
* **Number of jobs per tract** (from Census LEHD data) to represent daytime population.
* **Proximity to universities and major commercial zones.**
* **Density of other business types** (restaurants, retail) as a proxy for commercial activity.
